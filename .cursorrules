# SPOTS Development Protocol - Cursor AI Rules

## üö® MANDATORY: Session Start Protocol

**At the start of EVERY new chat/task, you MUST:**

1. **Read the entry point document:**
   ```
   read_file('docs/START_HERE_NEW_TASK.md')
   ```

2. **Determine task type:**
   - **Implementation task** (implement, create, build, add, start, proceed)
     ‚Üí Follow 40-minute context gathering protocol
   - **Status/progress query** (where are we, what's the status, how far along)
     ‚Üí Find and read ALL related documents (plan + complete + progress + status)

3. **Follow the protocol before any code:**
   - Do NOT skip to implementation
   - Do NOT skip context gathering
   - The 40-minute investment saves hours to days

---

## üéØ Implementation Task Triggers

When user says any of these, read `START_HERE_NEW_TASK.md` first:

- "implement [feature]"
- "create [component]"
- "build [feature]"
- "add [functionality]"
- "start [task]"
- "proceed with [phase]"
- "continue with [feature]"
- "let's do [task]"
- "work on [feature]"

**Protocol:**
```
1. Read START_HERE_NEW_TASK.md (docs/plans/methodology/START_HERE_NEW_TASK.md)
2. Read DOORS.md (docs/plans/philosophy_implementation/DOORS.md) - MANDATORY
3. Read OUR_GUTS.md - MANDATORY
4. Read SPOTS Philosophy (docs/plans/philosophy_implementation/SPOTS_PHILOSOPHY_AND_ARCHITECTURE.md) - MANDATORY
5. Read Development Methodology (docs/plans/methodology/DEVELOPMENT_METHODOLOGY.md) - MANDATORY
6. Check Master Plan (docs/MASTER_PLAN.md) for current execution sequence
7. Check Master Plan Tracker (docs/MASTER_PLAN_TRACKER.md) for all plans
8. Discover ALL plans (glob_file_search in docs/plans/)
9. Filter by recency + relevance
10. Read high-priority plans
11. Search existing implementations
12. Answer doors questions (What doors? When ready? Good key? Learning?)
13. Create TODO list
14. Communicate plan
15. Get user approval
16. Begin implementation (following methodology and philosophy)
```

---

## üîç Status Query Triggers

When user says any of these, read ALL related documents:

- "where are we with [topic]"
- "what's the status of [topic]"
- "how far along is [topic]"
- "what's complete in [topic]"
- "show me progress on [topic]"
- "update me on [topic]"

**Protocol:**
```bash
# ‚ö†Ô∏è CRITICAL: Never read just one document for status queries

# Find ALL related documents:
glob_file_search('**/*[topic]*.md')
glob_file_search('**/*[topic]*plan*.md')
glob_file_search('**/*[topic]*complete*.md')
glob_file_search('**/*[topic]*progress*.md')
glob_file_search('**/*[topic]*status*.md')
glob_file_search('**/*[topic]*summary*.md')

# Read ALL found documents, then synthesize comprehensive answer
```

**Example:**
```
User: "Where are we with week 1 of plan X?"

‚ùå WRONG: Read week_1_plan.md only
‚úÖ RIGHT: Find and read ALL:
  - week_1_plan.md
  - week_1_complete.md
  - week_1_progress.md
  - week_1_status.md
  
Then synthesize comprehensive answer.
```

---

## üìö Key Documentation

- **Entry Point:** `docs/plans/methodology/START_HERE_NEW_TASK.md` (read at start of EVERY task)
- **Quick Reference:** `docs/plans/methodology/SESSION_START_CHECKLIST.md`
- **Full Methodology:** `docs/plans/methodology/DEVELOPMENT_METHODOLOGY.md`
- **Master Plan:** `docs/MASTER_PLAN.md` (THE execution plan - single source of truth)
- **Master Plan Tracker:** `docs/MASTER_PLAN_TRACKER.md` (registry of all plans)
- **Master Plan System:** `.cursorrules_master_plan` (automated workflow for new features)
- **Integration Optimization:** `.cursorrules_integration_optimization` (phase-to-phase integration optimization)
- **SPOTS Philosophy:** `docs/plans/philosophy_implementation/SPOTS_PHILOSOPHY_AND_ARCHITECTURE.md` (CRITICAL - all work must align)
- **Development Guide:** `README_DEVELOPMENT.md`
- **Documentation Protocol:** `docs/agents/REFACTORING_PROTOCOL.md` (MANDATORY for all documentation)

---

## ü§ñ Master Plan System Integration

**When user says "I want to add [feature]" or "I want to implement [feature]":**

**Follow the automated workflow in:** `.cursorrules_master_plan`

**Key Steps:**
1. Create comprehensive plan document
2. Create plan folder with supporting docs
3. Add to Master Plan Tracker
4. Analyze for Master Plan integration (dependencies, priority, catch-up opportunities)
5. Insert into Master Plan at optimal position
6. Update execution sequence

**See:** `.cursorrules_master_plan` for complete automated workflow

---

## üîó Integration Optimization System

**When completing or starting a phase:**

**Follow the integration optimization rules in:** `.cursorrules_integration_optimization`

**Key Requirements:**
1. **Before completing a phase:**
   - Create output contracts document
   - Create breaking changes document (if applicable)
   - Update service registry
   - Write integration tests

2. **Before starting a phase:**
   - Create input requirements document
   - Verify all dependencies are available
   - Check service registry for locks
   - Complete integration checklist

3. **Before modifying a service:**
   - Check service registry for locks
   - Announce breaking changes (2 weeks before)
   - Lock service during modification
   - Update integration tests

**See:** `.cursorrules_integration_optimization` for complete integration optimization workflow  
**Reference:** `docs/INTEGRATION_OPTIMIZATION_PLAN.md` for complete guide

---

## ‚ö° Context Gathering is Mandatory

**Time Investment:** 40 minutes  
**Time Saved:** 50-90% (hours to days)  
**Proven ROI:** Multiple 99% time savings in actual implementations

**DO NOT skip context gathering to "save time" - it costs more later.**

---

## üìÅ Documentation Organization Protocol (MANDATORY)

**ALL agents MUST follow the Documentation Refactoring Protocol when creating or organizing documentation.**

### Refactoring Protocol (MANDATORY)

**Before creating ANY documentation, you MUST:**

1. **Read the refactoring protocol:**
   ```
   read_file('docs/agents/REFACTORING_PROTOCOL.md')
   ```

2. **Follow the mandatory folder structure:**
   - Phase-specific docs ‚Üí `docs/agents/prompts/[phase]/` and `docs/agents/tasks/[phase]/`
   - Shared docs ‚Üí `docs/agents/status/`, `docs/agents/protocols/`, `docs/agents/reference/`
   - Reports ‚Üí `docs/agents/reports/agent_X/[phase]/`

3. **Critical Rules:**
   - ‚úÖ **DO:** Create phase folders in `prompts/` and `tasks/`
   - ‚úÖ **DO:** Update SINGLE status tracker (`status/status_tracker.md`) with new phase sections
   - ‚úÖ **DO:** Organize reports by agent first, then phase
   - ‚ùå **DO NOT:** Create files in `docs/` root (e.g., `docs/PHASE_3_TASKS.md`)
   - ‚ùå **DO NOT:** Create phase-specific status trackers (use single file)
   - ‚ùå **DO NOT:** Create phase-specific protocols (use shared protocols)

4. **When creating documentation:**
   - Check if it's phase-specific or shared
   - Place in correct folder per protocol
   - Update status tracker (single file) if needed
   - Follow file naming conventions

**Reference:** `docs/agents/REFACTORING_PROTOCOL.md` - **MUST READ before creating documentation**

**This protocol applies to ALL phases (Phase 3+ and future phases).**

---

## üé® Project-Specific Rules

### Master Plan Notation (100% Adherence Required)
- ‚úÖ **ALWAYS use Phase.Section.Subsection (X.Y.Z) format** for all work references
- ‚úÖ **Format:** Phase X, Section Y, Subsection Z
- ‚úÖ **Shorthand:** X.Y.Z (e.g., 1.1.1 = Phase 1, Section 1, Subsection 1)
- ‚úÖ **Section only:** X.Y (e.g., 1.1 = Phase 1, Section 1)
- ‚ùå **NEVER use "Week" or "Day" terminology** - use "Section" and "Subsection" instead
- ‚ùå **NEVER mix old and new formats** - consistency is mandatory
- **This applies to:**
  - Master Plan references
  - Status tracker updates
  - Task assignments
  - Agent prompts
  - Completion reports
  - All documentation
- **Reference:** `docs/MASTER_PLAN.md` (Notation System section) for complete format guide

### Design Tokens (100% Adherence Required)
- ‚úÖ ALWAYS use `AppColors` or `AppTheme` for colors
- ‚ùå NEVER use direct `Colors.*` (will be flagged)
- This is non-negotiable per user memory

### Architecture
- System is **ai2ai only** (never p2p)
- All device interactions through personality learning AI
- AIs must always be self-improving (individual, network, ecosystem)

### Code Standards
- Zero linter errors before completion
- Zero deprecated API warnings - always use modern Flutter/Dart APIs
- Full integration (users can access features)
- Tests written
- Documentation complete

### Logging Standards (MANDATORY)
- ‚ùå **NEVER use `print()` or `debugPrint()` in production code**
- ‚úÖ **ALWAYS use `developer.log()` from `dart:developer` for logging**
- ‚úÖ Use appropriate log levels: `LogLevel.debug`, `LogLevel.info`, `LogLevel.warning`, `LogLevel.error`
- ‚úÖ Use structured logging with tags: `developer.log('message', name: 'ServiceName')`
- ‚úÖ Use existing `AppLogger` service when available for consistent logging patterns
- **Exception:** Test files may use `print()` for debugging test output only
- **Pattern:** 
  ```dart
  // ‚úÖ GOOD
  developer.log('User signed in', name: 'AuthService');
  
  // ‚ùå BAD
  print('User signed in');
  ```

### Error Handling Standards
- ‚úÖ **ALWAYS handle errors explicitly** - never silently swallow exceptions
- ‚úÖ Use try-catch blocks for async operations that can fail
- ‚úÖ Provide user-friendly error messages in UI
- ‚úÖ Log errors with context: `developer.log('Operation failed', error: e, stackTrace: st)`
- ‚úÖ Use Result/Either patterns for operations that can fail (where applicable)
- ‚ùå **NEVER use empty catch blocks** without logging
- **Pattern:** Catch specific exceptions when possible, generic `Exception` as fallback
- **Example:**
  ```dart
  // ‚úÖ GOOD
  try {
    await operation();
  } on NetworkException catch (e) {
    developer.log('Network error', error: e, name: 'ServiceName');
    showError('Connection failed. Please check your internet.');
  } catch (e, st) {
    developer.log('Unexpected error', error: e, stackTrace: st, name: 'ServiceName');
    showError('Something went wrong. Please try again.');
  }
  
  // ‚ùå BAD
  try {
    await operation();
  } catch (e) {
    // Silent failure
  }
  ```

### Import Organization
- ‚úÖ **Group imports in this order:**
  1. Dart SDK imports (`dart:...`)
  2. Flutter imports (`package:flutter/...`)
  3. Package imports (`package:...`)
  4. Relative imports (`../...`)
- ‚úÖ Use alphabetical ordering within each group
- ‚úÖ Separate groups with blank line
- ‚úÖ Remove unused imports (covered by cleanup philosophy)
- **Example:**
  ```dart
  // ‚úÖ GOOD
  import 'dart:async';
  import 'dart:convert';
  
  import 'package:flutter/material.dart';
  import 'package:flutter_bloc/flutter_bloc.dart';
  
  import 'package:spots/core/models/user.dart';
  import 'package:spots/core/services/auth_service.dart';
  
  import '../widgets/custom_button.dart';
  ```

### Dependency Injection Standards
- ‚úÖ **ALWAYS register new services in `lib/injection_container.dart`**
- ‚úÖ Use `registerLazySingleton` for services (not `registerSingleton`)
- ‚úÖ Register dependencies before dependents
- ‚úÖ Document service purpose in registration comment
- ‚úÖ Check for existing registration before adding: `if (!sl.isRegistered<Service>())`
- **Pattern:** Follow existing service registration patterns in `injection_container.dart`
- **Example:**
  ```dart
  // ‚úÖ GOOD
  // Register SalesTaxService (for tax calculation on events)
  sl.registerLazySingleton<SalesTaxService>(() => SalesTaxService(
    eventService: sl<ExpertiseEventService>(),
    paymentService: sl<PaymentService>(),
  ));
  ```

### File Organization Standards
- ‚úÖ **Follow Clean Architecture layers:**
  - `lib/core/` - Core business logic, models, services
  - `lib/data/` - Data sources, repositories (implementation)
  - `lib/domain/` - Use cases, repository interfaces
  - `lib/presentation/` - UI, BLoCs, widgets, pages
- ‚úÖ Group related files in subdirectories (e.g., `presentation/pages/auth/`)
- ‚úÖ Use descriptive file names: `create_event_page.dart` not `page1.dart`
- ‚úÖ One class per file (except for closely related classes like models)
- ‚úÖ Match file name to primary class name (e.g., `create_event_page.dart` ‚Üí `CreateEventPage`)
- **Reference:** Check existing structure before creating new files

### Code Documentation Standards
- ‚úÖ **ALWAYS document public APIs** (classes, methods, functions)
- ‚úÖ Use Dart doc comments (`///`) for public APIs
- ‚úÖ Include parameter descriptions, return values, exceptions
- ‚úÖ Document complex business logic with inline comments
- ‚úÖ Use `// TODO(Phase X.Y): Description` for planned work
- ‚úÖ Include usage examples for complex APIs
- ‚ùå **Don't document obvious code** (e.g., `/// Gets the name` for `getName()`)
- **Pattern:** Document WHY, not WHAT (code should be self-explanatory)
- **Example:**
  ```dart
  /// Calculate sales tax for an event
  ///
  /// **Flow:**
  /// 1. Get event details
  /// 2. Check if event type is taxable
  /// 3. Get tax rate for location
  /// 4. Calculate tax amount
  ///
  /// **Parameters:**
  /// - `eventId`: Event ID
  /// - `ticketPrice`: Ticket price
  ///
  /// **Returns:**
  /// SalesTaxCalculation with tax details
  Future<SalesTaxCalculation> calculateSalesTax({
    required String eventId,
    required double ticketPrice,
  }) async {
    // Implementation
  }
  ```

### Async/Await Standards
- ‚úÖ **ALWAYS use `async`/`await` instead of `.then()` chains**
- ‚úÖ **ALWAYS handle errors in async operations** (try-catch)
- ‚úÖ Use `FutureOr<T>` when a method can be sync or async
- ‚úÖ Check `mounted` before `setState()` in async callbacks (Flutter widgets)
- ‚úÖ Use `Completer` only when necessary (prefer `async`/`await`)
- ‚ùå **NEVER use `Future.value(null).then()`** - use `await` instead
- **Pattern:**
  ```dart
  // ‚úÖ GOOD
  Future<void> loadData() async {
    try {
      final data = await repository.fetch();
      if (mounted) {
        setState(() => _data = data);
      }
    } catch (e, st) {
      developer.log('Failed to load data', error: e, stackTrace: st);
    }
  }
  
  // ‚ùå BAD
  repository.fetch().then((data) {
    setState(() => _data = data);
  }).catchError((e) {
    // Silent failure
  });
  ```

### BLoC State Management
- ‚úÖ **ALWAYS extend `Bloc<Event, State>` for new BLoCs**
- ‚úÖ Use `emit()` instead of `yield` (modern BLoC API)
- ‚úÖ Handle all events in `on<EventType>()` handlers
- ‚úÖ Keep BLoCs focused - one BLoC per feature/domain
- ‚úÖ Use `BlocProvider` for dependency injection
- ‚úÖ Close BLoCs in `dispose()` or use `BlocProvider` auto-disposal
- ‚ùå **NEVER mutate state directly** - always emit new state
- ‚úÖ Use `BlocBuilder`/`BlocListener` appropriately in UI
- **Pattern:** Follow existing BLoC patterns in `presentation/blocs/`
- **Example:**
  ```dart
  // ‚úÖ GOOD
  class AuthBloc extends Bloc<AuthEvent, AuthState> {
    AuthBloc({required this.signInUseCase}) : super(AuthInitial()) {
      on<SignInRequested>(_onSignInRequested);
    }
    
    Future<void> _onSignInRequested(
      SignInRequested event,
      Emitter<AuthState> emit,
    ) async {
      emit(AuthLoading());
      try {
        final user = await signInUseCase(event.email, event.password);
        emit(Authenticated(user: user));
      } catch (e) {
        emit(AuthError(e.toString()));
      }
    }
  }
  ```

### Naming Conventions
- ‚úÖ Use `camelCase` for variables, methods, parameters
- ‚úÖ Use `PascalCase` for classes, enums, typedefs
- ‚úÖ Use `lowercase_with_underscores` for file names
- ‚úÖ Use descriptive names: `calculateSalesTax()` not `calc()`
- ‚úÖ Prefix private members with `_`: `_privateMethod()`
- ‚úÖ Use `is`, `has`, `can` prefixes for booleans: `isLoading`, `hasError`, `canEdit`
- ‚úÖ Use verb phrases for methods: `getUser()`, `createEvent()`, `validateInput()`
- ‚úÖ Use noun phrases for classes: `UserService`, `EventRepository`
- ‚ùå Avoid abbreviations unless widely understood (e.g., `id`, `url`, `api`)
- ‚ùå Avoid single-letter variables except in loops: `for (int i = 0; i < length; i++)`

### Code Review Checklist
**Before marking code complete, verify:**
- [ ] Zero linter errors
- [ ] Zero deprecated API warnings
- [ ] All tests pass
- [ ] No deprecated APIs used
- [ ] Proper error handling (no silent failures)
- [ ] Logging uses `developer.log()` (not `print()`)
- [ ] Follows architecture (ai2ai, offline-first, self-improving)
- [ ] Uses design tokens (AppColors/AppTheme)
- [ ] Documentation complete (public APIs documented)
- [ ] No unused code (unless documented exception)
- [ ] Service registered in DI if applicable
- [ ] Imports organized correctly
- [ ] File placed in correct architecture layer
- [ ] Naming conventions followed

### Feature Integration Workflow (MANDATORY)
**CRITICAL:** All new features/services/widgets/controllers MUST follow this integration workflow.

**Integration Sequence (MANDATORY ORDER):**

1. **Unit Tests First** ‚úÖ
   - Write unit tests for the new feature/service/widget/controller
   - All unit tests MUST pass before proceeding
   - Tests must cover core functionality, error handling, and edge cases
   - **DO NOT proceed to integration until unit tests pass**

2. **Integration Implementation** ‚úÖ
   - After unit tests pass, integrate the feature into the system
   - Register in dependency injection (if service/controller)
   - Wire into UI/other components (if widget/feature)
   - Update navigation/routing (if page/feature)
   - Replace old implementation with new one (if refactoring)

3. **Integration Tests** ‚úÖ
   - Write integration tests that verify the feature works in the system
   - Test integration points (service ‚Üí UI, controller ‚Üí service, etc.)
   - Test end-to-end workflows (if applicable)
   - All integration tests MUST pass before marking complete

4. **Verification** ‚úÖ
   - Run full test suite: `flutter test`
   - Verify no regressions introduced
   - Verify feature is accessible to users (if user-facing)
   - Check that all dependencies are satisfied

5. **Mark Complete** ‚úÖ
   - Only after steps 1-4 are complete
   - Update documentation
   - Update plan documents
   - Mark feature as complete

**Why This Order Matters:**
- ‚úÖ Unit tests verify the feature works in isolation
- ‚úÖ Integration verifies the feature works in the system
- ‚úÖ Integration tests catch integration issues early
- ‚úÖ Prevents broken features from being marked complete
- ‚úÖ Ensures users can actually access the feature

**Examples:**

‚ùå **WRONG:**
```dart
// 1. Create controller
class MyController { ... }

// 2. Integrate into UI immediately
onboardingPage.useController(MyController());

// 3. Write tests later (or never)
// Tests never written or fail
```

‚úÖ **RIGHT:**
```dart
// 1. Create controller
class MyController { ... }

// 2. Write unit tests
test('MyController validates input correctly', () { ... });
test('MyController handles errors gracefully', () { ... });
// ‚úÖ All unit tests pass

// 3. Integrate into system
sl.registerLazySingleton(() => MyController());
onboardingPage.useController(sl<MyController>());

// 4. Write integration tests
test('OnboardingPage uses MyController correctly', () { ... });
// ‚úÖ All integration tests pass

// 5. Mark complete
```

**Exception:**
- If integrating an existing, well-tested feature into a new context, you may skip unit tests (they already exist)
- Integration tests are still required for the new integration point

**Enforcement:**
- Code review will verify this workflow was followed
- Integration tests must exist and pass before feature completion
- Missing integration tests will block feature completion

### Quick Fixes Reference
**Common Issues & Solutions:**
- `Colors.*` ‚Üí Use `AppColors.*` or `AppTheme.*`
- `print()` ‚Üí Use `developer.log()` from `dart:developer`
- `tester.binding.window` ‚Üí Use `tester.view` (Flutter testing)
- `const Constructor()` error ‚Üí Remove `const` if constructor isn't const
- Unused code ‚Üí Remove or document exception per Code Cleanup Philosophy
- Missing service ‚Üí Register in `injection_container.dart`
- Deprecated API ‚Üí Check Flutter/Dart migration guides for modern equivalent
- Empty catch block ‚Üí Add error logging and user feedback

### Test Quality Standards (MANDATORY for ALL Tests)
**CRITICAL:** When writing tests, follow these quality standards to prevent low-value tests.

**Core Principle:** Test what the code DOES, not what it IS.

**‚úÖ DO Test:**
- **Behavior** - What happens when you call a method?
- **Business Logic** - Calculations, validation, transformations
- **Error Handling** - How code handles failures, invalid inputs
- **User Interactions** - Widget taps, input, gestures, state changes
- **Round-trip JSON** - Serialization AND deserialization together
- **Edge Cases** - Empty states, error states, boundary conditions

**‚ùå DON'T Test:**
- **Property Assignment** - `expect(model.id, equals('1'))` - Tests language, not behavior
- **Constructor-Only** - `test('should create', () { expect(obj, isNotNull); })` - Tests Dart works, not your code
- **Field-by-Field JSON** - Individual `expect(json['field'], ...)` checks - Use round-trip instead
- **Trivial Null Checks** - `expect(value, isNotNull)` without behavior - Test behavior with null
- **Over-Granular UI** - Separate tests for each UI element - Consolidate into comprehensive tests

**Test Patterns:**
- **Comprehensive Test Blocks:** Combine related checks into single tests
- **Round-Trip JSON:** `final restored = Model.fromJson(original.toJson()); expect(restored, equals(original));`
- **Behavior-Driven:** Test what the code does, not how it's structured
- **Error Handling:** Always test error cases, not just happy path

**Examples:**

‚ùå **BAD:**
```dart
test('should create model', () {
  final model = Model(id: '1', name: 'Test');
  expect(model.id, equals('1'));
  expect(model.name, equals('Test'));
});
```

‚úÖ **GOOD:**
```dart
test('should validate coordinates and throw ArgumentError for invalid latitude', () {
  expect(() => Spot(latitude: 200, longitude: 0), throwsArgumentError);
});

test('should serialize and deserialize correctly (round-trip)', () {
  final spot = Spot(id: '1', name: 'Test', latitude: 40.0, longitude: -74.0);
  final restored = Spot.fromJson(spot.toJson());
  expect(restored, equals(spot));
});
```

**Resources:**
- **Full Guide:** `docs/plans/test_refactoring/TEST_WRITING_GUIDE.md` - Comprehensive guide with examples
- **Quick Reference:** `docs/plans/test_refactoring/TEST_QUALITY_QUICK_REFERENCE.md` - One-page checklist
- **Templates:** `test/templates/` - Use templates which include quality guidelines
- **Quality Checker:** `dart run scripts/check_test_quality.dart [file]` - Verify test quality

**Before committing tests:**
- [ ] Tests focus on behavior, not properties
- [ ] No constructor-only tests
- [ ] JSON tests use round-trip pattern
- [ ] Related checks consolidated into single tests
- [ ] Error handling cases included
- [ ] Test names are descriptive and behavior-focused
- [ ] File has documentation header with purpose

**Pre-commit hook will flag violations automatically.**

### Experiment Testing Standards (MANDATORY for ALL Experiments)
**CRITICAL:** Experiments must test the REAL implementation, never simplified approximations.

**Core Principle:** Experiments should ALWAYS test what is actually being applied in production, even if testing individual features in isolation.

**‚úÖ REQUIRED:**
- **Real Implementation Logic** - Experiments must use the exact same calculations, formulas, and logic as the production code
- **Full Feature Testing** - Test complete implementations, not simplified versions
- **Isolation When Needed** - If testing individual features, still use the real implementation of that feature (not a simplified approximation)
- **Exact Formula Matching** - Quantum state calculations, compatibility formulas, and all mathematical operations must match production code exactly

**‚ùå FORBIDDEN:**
- **Simplified Calculations** - Never use simplified approximations (e.g., distance decay instead of full quantum state inner product)
- **Linear Approximations** - Never use linear approximations of nonlinear quantum operations
- **Mock Implementations** - Never use mock or stub implementations in experiments (use real logic)
- **Partial Testing** - Never test only part of a feature with simplified logic

**Examples:**

‚ùå **BAD:**
```python
# Simplified distance decay (NOT the real implementation)
location_compatibility = exp(-decay_rate * distance_km)
```

‚úÖ **GOOD:**
```python
# Real quantum state inner product (matches production code)
location_state = create_location_quantum_state(lat, lon, type, accessibility, vibe)
compatibility = abs(inner_product(location_state_a, location_state_b)) ** 2
```

**When Isolating Features:**
- ‚úÖ **DO:** Test the real implementation of that specific feature in isolation
- ‚úÖ **DO:** Use the exact same quantum state calculations, formulas, and logic
- ‚ùå **DON'T:** Simplify the feature's implementation for testing
- ‚ùå **DON'T:** Use approximations or linear versions of nonlinear operations

**Experiment Implementation Checklist:**
- [ ] Experiment uses exact same formulas as production code
- [ ] Quantum state calculations match production implementation
- [ ] No simplified approximations used
- [ ] All mathematical operations match production code
- [ ] If isolating features, still uses real implementation of that feature
- [ ] Experiment logic documented with references to production code

**Before creating experiments, ask yourself:**
- Am I using the exact same calculations as production?
- Am I testing the real implementation or a simplified version?
- Would this experiment validate what users actually experience?
- Can I use the real implementation logic even if testing in isolation?

### Test Implementation Requirements (MANDATORY for ALL Tests)
**CRITICAL:** Tests must test real functionality. Mocks and stubs have strict limitations.

**Core Principle:** Test real behavior with real dependencies whenever possible.

**‚úÖ REQUIRED:**
- **Real Functionality** - Tests must exercise actual code paths and real dependencies
- **Real Dependencies** - Use actual services, repositories, and data sources in tests
- **Integration Testing** - Prefer integration tests that test multiple components together
- **Real Data** - Use real data structures, real serialization, real validation

**‚ö†Ô∏è MOCKS - Rare Cases Only (Requires Approval):**
- Mocks are **ONLY** acceptable in specific rare cases
- **MANDATORY:** Before using any mock, you MUST:
  1. Explain why a mock is necessary (what makes this a rare case)
  2. Explain what real functionality would be tested if not for the mock
  3. Get explicit user approval before implementing
- **Examples of potentially acceptable rare cases:**
  - External APIs that charge per request and cannot be called in tests
  - Hardware dependencies that don't exist in test environment
  - Time-dependent operations that require specific timing control
  - Network failures that are difficult to simulate with real dependencies
- **Even in rare cases:** Prefer real implementations with test doubles (fake implementations) over mocks

**‚ùå STUBS - NEVER ACCEPTABLE:**
- Stubs are **FORBIDDEN** in all cases
- Never use stubs as a replacement for real functionality
- If you need to avoid real dependencies, use real test implementations or get approval for mocks (following the approval process above)

**Test Implementation Checklist:**
- [ ] Tests use real functionality and real dependencies
- [ ] No stubs used anywhere
- [ ] If mocks are used, approval was obtained with explanation
- [ ] Mock usage is documented with justification
- [ ] Real behavior is tested, not just mocked behavior

**Before using mocks, ask yourself:**
- Can I use a real implementation instead?
- Can I create a test implementation (fake) that behaves like the real thing?
- Is this truly a rare case that requires a mock?
- Have I explained and received approval for the mock?

### Philosophy
- **CRITICAL:** Reference `docs/plans/philosophy_implementation/SPOTS_PHILOSOPHY_AND_ARCHITECTURE.md` for core philosophy
- **Core Principle:** "Doors, not badges" - Authentic contributions, not gamification
- **Code Cleanup Philosophy:**
  - **General Rule:** Remove unused code to maintain codebase cleanliness
  - **Exceptions - Keep unused code ONLY if:**
    1. **Planned Feature Setup** - Code is documented as preparation for a specific planned feature
       - Must include: Reference to plan document (e.g., `docs/plans/phase_X/feature_name.md`)
       - Must include: Expected usage date/phase
       - Example comment: `// TODO(Phase 3.2): Event analytics - See docs/plans/phase_3/event_analytics.md`
    2. **API Contracts** - Interfaces, abstract classes, or stubs required for API compatibility
    3. **Active Experimentation** - Part of an active experimental branch (with clear branch name)
    4. **Auto-Generated Code** - Code generated by tools (marked with `// ignore: unused_element` or similar)
  - **Always Remove:**
     - Code determined unnecessary during code review or refactoring
     - Dead code with no documented purpose
     - Obsolete implementations replaced by newer code
     - Code unused for >6 months without meeting exception criteria
  - **Documentation Requirement:** All kept unused code MUST have a comment explaining:
     - Why it's kept (which exception applies)
     - When it will be used (specific phase/date if known)
     - Reference to related plan/documentation
  - **Cleanup Process:**
     - Review unused code quarterly
     - During code review/refactoring: Remove unused code if determined unnecessary
     - Remove code unused for >6 months unless it meets exception criteria above
     - Move truly experimental code to feature branches, not main
  - **Linter Suppression:** Use `// ignore: unused_element` only for documented exceptions
- Auto-generated docs are NOT deletable
- All work must align with SPOTS philosophy

---

## üö® Critical Warnings

**STOP and clarify if:**
- [ ] Can't find main plan document
- [ ] Task conflicts with existing plan
- [ ] Multiple plans with contradictory specs
- [ ] Unclear where code should be placed
- [ ] Can't determine dependencies
- [ ] Found existing implementation but specs differ

**DO NOT proceed until clarified.**

---

## ‚úÖ Before Starting ANY Implementation

**Confirm ALL of these (MANDATORY):**
- [ ] I have read START_HERE_NEW_TASK.md (docs/plans/methodology/START_HERE_NEW_TASK.md)
- [ ] I have read DOORS.md (docs/plans/philosophy_implementation/DOORS.md) - MANDATORY
- [ ] I have read OUR_GUTS.md - MANDATORY
- [ ] I have read SPOTS Philosophy (docs/plans/philosophy_implementation/SPOTS_PHILOSOPHY_AND_ARCHITECTURE.md) - MANDATORY
- [ ] I have read Development Methodology (docs/plans/methodology/DEVELOPMENT_METHODOLOGY.md) - MANDATORY
- [ ] I have read Documentation Refactoring Protocol (docs/agents/REFACTORING_PROTOCOL.md) - MANDATORY for documentation
- [ ] I have checked Master Plan (docs/MASTER_PLAN.md) for execution sequence
- [ ] I have checked Master Plan Tracker (docs/MASTER_PLAN_TRACKER.md) for all plans
- [ ] I have discovered ALL relevant plans (in docs/plans/ folders)
- [ ] I have filtered plans by recency + relevance
- [ ] I have read high-priority related plans
- [ ] I have answered doors questions (What doors? When ready? Good key? Learning?)
- [ ] I have checked for conflicts
- [ ] I have searched for existing implementations
- [ ] I understand the architecture (ai2ai only, offline-first, self-improving)
- [ ] I have created a TODO list
- [ ] I have communicated my plan to user
- [ ] User has approved the approach

**If ANY checkbox is unchecked, DO NOT START CODING.**

**If ANY checkbox is unchecked, DO NOT START CODING.**

---

## üìä Success Metrics (Proven)

Following this protocol:
- Phase 1 Integration: 40 min ‚Üí Saved 5 days (99%)
- Optional Enhancements: 30 min ‚Üí Saved 3 days (85%)
- Phase 2.1: 20 min ‚Üí Saved 11 days (99.5%)

**NOT following this protocol:**
- Risk duplicating existing work
- Risk wrong architecture/placement
- 2-10x longer implementation time

---

## üéØ The Golden Rule

```
40 minutes of context gathering
saves
40 hours of implementation

ALWAYS invest the 40 minutes.
```

---

---

## üß™ Experiment Data Requirements (MANDATORY)

**CRITICAL:** All experiments MUST use real Big Five OCEAN data converted to SPOTS 12 dimensions.

### **Mandatory Rule (Effective December 30, 2025):**

**ALL experiments MUST:**
1. ‚úÖ **Use `load_and_convert_big_five_to_spots()` from `shared_data_model.py`**
2. ‚úÖ **Load raw Big Five OCEAN data (100k+ real examples)**
3. ‚úÖ **Convert to SPOTS 12 dimensions using `BigFiveToSpotsConverter`**
4. ‚úÖ **Document that experiments use real data (not synthetic)**

**FORBIDDEN:**
- ‚ùå **DO NOT use synthetic data generation for personality profiles**
- ‚ùå **DO NOT use `generate_integrated_user_profile()` or similar synthetic generators**
- ‚ùå **DO NOT hardcode personality dimensions**

### **Historical Note:**

**Experiments completed before December 30, 2025 used synthetic data.**
- All new experiments must use real Big Five data
- When referencing old experiments, clearly state they used synthetic data
- When updating old experiments, migrate them to use real Big Five data

### **Standard Pattern:**

```python
from shared_data_model import load_and_convert_big_five_to_spots
from pathlib import Path

# Get project root
project_root = Path(__file__).parent.parent.parent.parent.parent

# Load and convert Big Five OCEAN to SPOTS 12
spots_profiles = load_and_convert_big_five_to_spots(
    max_profiles=1000,  # Or None for all available
    data_source='auto',  # Tries CSV first, then JSON
    project_root=project_root
)

# Each profile has:
# - user_id
# - dimensions: {all 12 SPOTS dimensions}
# - original_data.big_five: {OCEAN scores}
```

### **Data Sources:**

1. **Primary:** `data/raw/big_five.csv` - Raw Big Five OCEAN data (100k+ examples)
2. **Fallback:** `data/raw/big_five_spots.json` - Extracts original_data.big_five

### **Conversion:**

- Uses `BigFiveToSpotsConverter` from `scripts/personality_data/converters/big_five_to_spots.py`
- Converts OCEAN (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) ‚Üí SPOTS 12 dimensions
- All values normalized to 0.0-1.0 range

### **Documentation Requirement:**

When creating or updating experiments:
- ‚úÖ State that experiments use real Big Five OCEAN data
- ‚úÖ Reference `load_and_convert_big_five_to_spots()` function
- ‚úÖ Note that experiments before December 30, 2025 used synthetic data
- ‚úÖ Include data source and conversion method in experiment documentation

---

**Last Updated:** December 30, 2025  
**Status:** Active - Mandatory for all AI assistants working on SPOTS

